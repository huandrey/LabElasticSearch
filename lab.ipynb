{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratório Elastic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto\n",
    "O objetivo deste laboratório é explorar diferentes mecanismos de busca dentro e fora do Elastic Search!\n",
    "Para isto, iremos explorar uma base de verificações de notícia de uma agência de checagem, chamada [Lupa](https://lupa.uol.com.br/).\n",
    "O papel de uma agência de checagem é analisar uma notícia e verificar sua veracidade, gerar um veredito e retornar sua análise.\n",
    "\n",
    "Neste laboratório, iremos nos preocupar apenas com o texto da análise e em como recuperá-los através de diferentes estratégias de busca.\n",
    "\n",
    "## Tarefas\n",
    "### Tarefa 1\n",
    "- Cada uma das equipes receberá 2 queries fixas, chamadas de QF1 e QF2, e a tarefa do grupo será a criação de mais 2 queries, chamadas de QP1 e QP2. As queries devem seguir o formato de uma pergunta ou declaração textual e ela será usada na próxima tarefa para realizar buscas. As equipes podem se inspirar nas notícias fornecidas (presentes no csv da tarefa 2) para montá-las. Cada query deve ser composta por até 100 caracteres.\n",
    "- A equipe deve enviar suas QP1 e QP2 em um formulário que será disponibilizado no classroom e no discord.\n",
    "\n",
    "### Tarefa 2\n",
    "- Após a criação das QP1 e QP2, cada equipe possuirá 4 queries (QF1; QF2; QP1 e QP2).\n",
    "- Cada grupo irá realizar 4 tipos de busca. Uma busca léxica com BM25 (pelo ElasticSearch), uma busca semântica (pelo ElasticSearch), uma busca híbrida (manualmente utilizando as duas buscas anteriores) e uma estratégia de busca de sua preferência (neste lab ela será chamada de busca criativa), diferente das anteriores.\n",
    "- As buscas léxica e semântica já estão implementadas, os grupos devem gerar a implementação das buscas híbridas e da busca criativa.\n",
    "- A busca criativa será a busca usada para a competição!\n",
    "- Cada grupo durante a implementação de suas buscas deve testar diferentes pré-processamentos nos dados para verificar como os resultados podem melhorar. Alguns pré-processamentos já foram implementados, mas os grupos não precisam se limitar aos pré-processamentos apresentados. Vocês podem buscar na internet implementações de outros pré-processamentos, criar padrões regex, etc. Observe que os dados precisarão ser reindexados no ElasticSearch sempre que os pré-processamentos forem modificados (inseridos, removidos ou mudados de ordem)!\n",
    "- Enquanto vocês testam seus pré-processamentos e algoritmos de busca, ao analisar os resultados obtidos para uma determinada query, anotem o nível de relevância de cada documento lido em relação à query. Observe que esse procedimento pode ser realizado continuamente durante o processo de implementação, pois a relevância de um documento para uma query independe de implementação de buscadores. Essa anotação deve ser realizada (online) em uma planilha no google drive, que será fornecida pela organização do Lab. Caso mais de um integrante do grupo anote valores diferentes na planilha, não tem problemas. Nesse caso, iremos considerar a média dos valores.\n",
    "    - A planilha tem o seguinte formato:\n",
    "        - doc_id, query_id, relevance\n",
    "        - 120, QP1, 2\n",
    "        - 487, QP1, 1\n",
    "        - ...\n",
    "    - Cada busca deve possuir pelo menos 10 resultados anotados.\n",
    "    - Não modifique o código que realiza o carregamento dos dados para que o doc_id seja consistente com os demais grupos!\n",
    "    - A rotulação deve possui uma gradação em 3 níveis:\n",
    "        - 0: Não é Relevante\n",
    "        - 1: Pouco Relevante\n",
    "        - 2: Muito Relevante \n",
    "- A entrega desta tarefa será feita através de um formulário para entregar um .zip contendo todo o repositório e o código utilizado autocontido (com listagem das dependências utilizadas no requirements.txt se necessário) e suas buscas implementadas. Este código será reexecutado, então organize o código para que ele possa ser reexecutado em outra máquina.\n",
    "- Quando esgotar o prazo de envio da tarefa a planilha será bloqueada para modificações.\n",
    "- A partir deste momento, nenhum grupo poderá alterar suas buscas novamente, então tenham ciência que esta será sua implementação final que será usada para a competição.\n",
    "\n",
    "### Tarefa 3\n",
    "- O grupo receberá (pelo discord) 3 queries adicionais (QA1; QA2 e QA3).\n",
    "- A tarefa do grupo será a execução do MESMO CÓDIGO submetido na tarefa anterior com estas 3 queries e a anotação dos dados (a planilha de anotações será disponibilizada pelo discord).\n",
    "- Nesta etapa, o grupo NÃO PODE FAZER ALTERAÇÕES nos pré-processamentos definidos ou nas implementações de suas buscas.\n",
    "- Quando esgotar o prazo de envio da tarefa a planilha será bloqueada para modificações.\n",
    "- IMPORTANTE: O seu código entregue na tarefa 2 será reexecutado com estas 3 queries (assim como você fez) para garantir que os resultados batem com os seus. Os grupos que mudarem suas buscas ou pré-processamentos na tarefa 3 terão sua nota penalizada e serão desclassificados da competição.\n",
    "\n",
    "## Competição\n",
    "A competição será realizada através da comparação dos resultados das buscas criativas em uma base de documentos (corpus) utilizada pela organização do Lab.\n",
    "Para que você atinja um bom desempenho na competição, é importante se atentar ao seu processo de criação de queries e na qualidade da rotulação dos documentos, pois elas serão seus guias do quão boa sua busca está se saindo!\n",
    "\n",
    "Como métrica de avaliação, esta competição irá utilizar a média do NDCG calculado para cada query. \n",
    "\n",
    "## Ferramental\n",
    "Para executar este lab não é necessário uma máquina com GPU, mas a máquina deve ter capacidade de virtualização, além de possuir o Docker e o Python instalado.\n",
    "\n",
    "Será utilizado o ElasticSearch (e opcionalmente o Kibana) no ambiente docker.\n",
    "\n",
    "Para realizar o lab é recomendado o uso de Python 3.12, além de um venv ou ambiente conda.\n",
    "\n",
    "Você deve instalar as dependências do requirements.txt.\n",
    "\n",
    "## Detalhes\n",
    "Ao executar o docker compose, além de ser levantado o ElasticSearch, também é levantada uma interface visual chamada Kibana.\n",
    "\n",
    "O Kibana é um frontend para facilitar o acionamento de algumas operações do ElasticSearch e controle de configurações específicas, observar métricas etc. Ela pode ser utilizada para fins de debug. Para quem tiver curiosidade, acesse o URI: http://localhost:5601 após levantar o serviço com o docker compose.\n",
    "\n",
    "## Dúvidas\n",
    "Caso tenham dúvidas, é só entrar em contato pelo nosso servidor do Discord."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "# Código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Passos de preparação do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy==3.8.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (3.8.4)\n",
      "Requirement already satisfied: pandas==2.2.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: elasticsearch==8.17.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (8.17.2)\n",
      "Requirement already satisfied: sentence-transformers==3.4.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: nltk==3.9.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (3.9.1)\n",
      "Requirement already satisfied: scikit-learn==1.6.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
      "Requirement already satisfied: ipykernel==6.29.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (6.29.5)\n",
      "Requirement already satisfied: unidecode==1.3.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (1.3.8)\n",
      "Requirement already satisfied: xlsxwriter==3.2.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (3.2.2)\n",
      "Requirement already satisfied: openpyxl==3.1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (3.1.5)\n",
      "Requirement already satisfied: certifi==2025.1.31 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (2025.1.31)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (77.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy==3.8.*->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas==2.2.*->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas==2.2.*->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas==2.2.*->-r requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from elasticsearch==8.17.2->-r requirements.txt (line 3)) (8.17.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers==3.4.*->-r requirements.txt (line 4)) (4.50.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers==3.4.*->-r requirements.txt (line 4)) (2.6.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers==3.4.*->-r requirements.txt (line 4)) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers==3.4.*->-r requirements.txt (line 4)) (0.29.3)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers==3.4.*->-r requirements.txt (line 4)) (10.4.0)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk==3.9.*->-r requirements.txt (line 5)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk==3.9.*->-r requirements.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk==3.9.*->-r requirements.txt (line 5)) (2024.11.6)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn==1.6.*->-r requirements.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: appnope in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel==6.29.*->-r requirements.txt (line 8)) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel==6.29.*->-r requirements.txt (line 8)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel==6.29.*->-r requirements.txt (line 8)) (1.8.13)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel==6.29.*->-r requirements.txt (line 8)) (9.0.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel==6.29.*->-r requirements.txt (line 8)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel==6.29.*->-r requirements.txt (line 8)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel==6.29.*->-r requirements.txt (line 8)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel==6.29.*->-r requirements.txt (line 8)) (1.6.0)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel==6.29.*->-r requirements.txt (line 8)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel==6.29.*->-r requirements.txt (line 8)) (26.3.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel==6.29.*->-r requirements.txt (line 8)) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipykernel==6.29.*->-r requirements.txt (line 8)) (5.14.3)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openpyxl==3.1.*->-r requirements.txt (line 11)) (2.0.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch==8.17.2->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.4.*->-r requirements.txt (line 4)) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.4.*->-r requirements.txt (line 4)) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.4.*->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers==3.4.*->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: decorator in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.*->-r requirements.txt (line 8)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.*->-r requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.*->-r requirements.txt (line 8)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.*->-r requirements.txt (line 8)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.*->-r requirements.txt (line 8)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.*->-r requirements.txt (line 8)) (2.18.0)\n",
      "Requirement already satisfied: stack_data in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.*->-r requirements.txt (line 8)) (0.6.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.29.*->-r requirements.txt (line 8)) (4.3.7)\n",
      "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.8.*->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.*->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.8.*->-r requirements.txt (line 1)) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.*->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.*->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.8.*->-r requirements.txt (line 1)) (3.8)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy==3.8.*->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy==3.8.*->-r requirements.txt (line 1)) (0.1.5)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.*->-r requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers==3.4.*->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers==3.4.*->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers==3.4.*->-r requirements.txt (line 4)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers==3.4.*->-r requirements.txt (line 4)) (0.5.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy==3.8.*->-r requirements.txt (line 1)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy==3.8.*->-r requirements.txt (line 1)) (13.8.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy==3.8.*->-r requirements.txt (line 1)) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy==3.8.*->-r requirements.txt (line 1)) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->spacy==3.8.*->-r requirements.txt (line 1)) (2.1.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.29.*->-r requirements.txt (line 8)) (0.8.4)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.8.*->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel==6.29.*->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel==6.29.*->-r requirements.txt (line 8)) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.8.*->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy==3.8.*->-r requirements.txt (line 1)) (1.17.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.29.*->-r requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.29.*->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.29.*->-r requirements.txt (line 8)) (0.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.8.*->-r requirements.txt (line 1)) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/huandrey/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/huandrey/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import warnings\n",
    "import subprocess\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import OrderedDict\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import sklearn\n",
    "import ssl\n",
    "\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import spacy\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 0: Subir Stack do Elastic (ElasticSearch e Kibana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download pt_core_news_sm # Caso o comando não funcione, execute-o no terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time=\"2025-03-21T22:56:26-03:00\" level=warning msg=\"/Users/huandrey/www/ufcg/nono_periodo/rec-info/LabElasticSearch/docker-compose.yaml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion\"\n",
      " Container labelasticsearch-setup-1  Created\n",
      " Container labelasticsearch-es01-1  Created\n",
      " Container labelasticsearch-kibana-1  Created\n",
      " Container labelasticsearch-setup-1  Starting\n",
      " Container labelasticsearch-setup-1  Started\n",
      " Container labelasticsearch-setup-1  Waiting\n",
      " Container labelasticsearch-setup-1  Healthy\n",
      " Container labelasticsearch-es01-1  Starting\n",
      " Container labelasticsearch-es01-1  Started\n",
      " Container labelasticsearch-es01-1  Waiting\n",
      " Container labelasticsearch-es01-1  Healthy\n",
      " Container labelasticsearch-kibana-1  Starting\n",
      " Container labelasticsearch-kibana-1  Started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call([\"docker\", \"compose\", \"up\", \"-d\"])\n",
    "# Se esse comando falhar ou retornar 1, execute-o diretamente no terminal para identificar o erro.\n",
    "# PS: O docker deve estar instalado e rodando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 1: Baixar dados do Lupa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de dados de notícias da Lupa\n",
    "url = \"https://docs.google.com/uc?export=download&confirm=t&id=1W067Md2EbvVzW1ufzFg17Hf7Y9cCZxxr\"\n",
    "filename = \"articles_lupa_lab_elasticsearch.zip\"\n",
    "data_path = \"data\"\n",
    "zip_file_path = f\"{data_path}/{filename}\"\n",
    "\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "# Baixa o zip\n",
    "with open(zip_file_path, \"wb\") as f:\n",
    "    f.write(requests.get(url, allow_redirects=True).content)\n",
    "\n",
    "# Extrai o csv do zip\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_path)\n",
    "    \n",
    "output_file = f\"{data_path}/articles_lupa.csv\"\n",
    "assert os.path.exists(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 2: Pré-processar os dados e gerar embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementações de pré-processamentos de texto. Modifiquem, adicionem, removam conforme necessário.\n",
    "class Preprocessors:\n",
    "    STOPWORDS = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.spacy_nlp = spacy.load(\"pt_core_news_sm\") # Utiliza para lematização\n",
    "        \n",
    "    # Remove stopwords do português\n",
    "    def remove_stopwords(self, text):\n",
    "        # Tokeniza as palavras\n",
    "        tokens = word_tokenize(text)\n",
    "        # Remove as stop words\n",
    "        tokens = [word for word in tokens if word not in self.STOPWORDS]\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    # Realiza a lematização\n",
    "    def lemma(self, text):\n",
    "        return \" \".join([token.lemma_ for token in self.spacy_nlp(text)])\n",
    "    \n",
    "    # Realiza a stemização\n",
    "    def porter_stemmer(self, text):\n",
    "        # Tokeniza as palavras\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        for index in range(len(tokens)):\n",
    "            # Realiza a stemização\n",
    "            stem_word = self.stemmer.stem(tokens[index])\n",
    "            tokens[index] = stem_word\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    # Transforma o texto em lower case\n",
    "    def lower_case(self, str):\n",
    "        return str.lower()\n",
    "\n",
    "    # Remove urls com regex\n",
    "    def remove_urls(self, text):\n",
    "        url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "        without_urls = re.sub(pattern=url_pattern, repl=' ', string=text)\n",
    "        return without_urls\n",
    "\n",
    "    # Remove números com regex\n",
    "    def remove_numbers(self, text):\n",
    "        number_pattern = r'\\d+'\n",
    "        without_number = re.sub(pattern=number_pattern,\n",
    "    repl=\" \", string=text)\n",
    "        return without_number\n",
    "\n",
    "    # Converte caracteres acentuados para sua versão ASCII\n",
    "    def accented_to_ascii(self, text):\n",
    "        text = unidecode.unidecode(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geração de embeddings finalizada.\n"
     ]
    }
   ],
   "source": [
    "# Carregar o modelo gerador de embeddings\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Caminho para salvar o dataframe de notícias\n",
    "data_df_path = \"data/data_df.pkl\"\n",
    "\n",
    "# Selecione diferentes pré-processamentos\n",
    "# Exemplo:\n",
    "\"\"\"\n",
    "preprocessor = Preprocessors()\n",
    "preprocessing_steps = [\n",
    "    preprocessor.remove_urls,\n",
    "    preprocessor.remove_stopwords,\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "preprocessing_steps = [\n",
    "    # Adicione os pré-processamentos aqui\n",
    "]\n",
    "\n",
    "RECREATE_DF = True\n",
    "\n",
    "# Cria o data frame se ele já existir ou se a variável RECREATE_INDEX for verdadeira\n",
    "# Ou (exclusivo) carrega o dataframe salvo\n",
    "if not os.path.exists(data_df_path) or RECREATE_DF:    \n",
    "    df = pd.read_csv(output_file, sep=\";\")[[\"Título\", \"Texto\", \"Data de Publicação\"]]\n",
    "    df[\"Data de Publicação\"] = df[\"Data de Publicação\"].apply(lambda str_date: datetime.strptime(str_date.split(\" - \")[0], \"%d.%m.%Y\"))\n",
    "    df.sort_values(\"Data de Publicação\", inplace=True, ascending=False)\n",
    "    df[\"Embeddings\"] = [None] * len(df)\n",
    "    df[\"doc_id\"] = df.reset_index(drop=True).index\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        texto_completo = row[\"Texto\"].strip() + \"\\n\" + row[\"Título\"].strip()\n",
    "        \n",
    "        df.at[i, \"Texto completo\"] = texto_completo\n",
    "        texto_processado = texto_completo\n",
    "        for preprocessing_step in preprocessing_steps:\n",
    "            texto_processado = preprocessing_step(texto_processado)\n",
    "        \n",
    "        df.at[i, \"Texto processado\"] = texto_processado\n",
    "        embeddings = model.encode(texto_completo).tolist()\n",
    "        df.at[i, \"Embeddings\"] = embeddings\n",
    "        \n",
    "    print(\"Geração de embeddings finalizada.\")\n",
    "    \n",
    "    with open(data_df_path, \"wb\") as f:\n",
    "        df.to_pickle(f)\n",
    "else:\n",
    "    with open(data_df_path, \"rb\") as f:\n",
    "        df = pd.read_pickle(f)\n",
    "    print(\"Dataframe carregado de arquivo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 3: Indexar dados no ElasticSearch (Lembrem-se de reindexar os dados se os pré-processamentos mudarem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\n",
    "    hosts = [{'host': \"localhost\", 'port': 9200, \"scheme\": \"https\"}],\n",
    "    basic_auth=(\"elastic\",\"elastic\"),\n",
    "    verify_certs = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índice 'verificacoes_lupa' criado.\n",
      "Índice preenchido.\n",
      "Indexação finalizada.\n"
     ]
    }
   ],
   "source": [
    "RECREATE_INDEX = True\n",
    "\n",
    "index_name = \"verificacoes_lupa\"\n",
    "\n",
    "# Se a flag for True e se o índice existir, ele é deletado\n",
    "if RECREATE_INDEX and es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "    print(f\"Índice '{index_name}' deletado.\")\n",
    "\n",
    "# Cria o índice e popula com os dados\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(index=index_name, mappings={\n",
    "        \"properties\": {\n",
    "            \"doc_id\": {\"type\": \"integer\"},\n",
    "            \"full_text\": {\"type\": \"text\"},\n",
    "            \"processed_text\": {\"type\": \"text\"},\n",
    "            \"embeddings\": {\"type\": \"dense_vector\", \"dims\": 384}\n",
    "        }\n",
    "    })\n",
    "    print(f\"Índice '{index_name}' criado.\")\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        es.index(index=index_name, id=row[\"doc_id\"], body={\n",
    "            \"doc_id\": row[\"doc_id\"],\n",
    "            \"full_text\": row[\"Texto completo\"],\n",
    "            \"processed_text\": row[\"Texto processado\"],\n",
    "            \"embeddings\": row[\"Embeddings\"]\n",
    "        })\n",
    "    print(\"Índice preenchido.\")\n",
    "\n",
    "print(\"Indexação finalizada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 1: Criar query\n",
    "Crie as queries da tarefa 1 (QP1 e QP2), as queries devem ser perguntas ou declarações de até 100 caracteres.\n",
    "\n",
    "Inspire-se nas notícias presente no csv (data/articles_lupa.csv) para gerar queries interessantes.\n",
    "\n",
    "Submetam as queries ao formulário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2: Implementação e realização das buscas\n",
    "Agora que você montou suas queries, realize cada uma das buscas para cada uma das queries (QF1; QF2; QP1 e QP2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estas serão as queries QF1 e QF2\n",
    "with open(\"data/queries_fixadas.txt\", \"r\") as f:\n",
    "    queries_fixadas = [line.strip() for line in f.readlines()]\n",
    "    assert len(queries_fixadas) == 4\n",
    "    QF1 = queries_fixadas[0]\n",
    "    QF2 = queries_fixadas[1]\n",
    "    \n",
    "# Preencha aqui as queries do grupo\n",
    "QP1 = \"Investigações sobre a tentativa de golpe de estado no Brasil.\"\n",
    "QP2 = \"Houve fraude nas eleições brasileiras de 2022?\"\n",
    "\n",
    "queries = OrderedDict()\n",
    "queries[\"QF1\"] = QF1\n",
    "queries[\"QF2\"] = QF2\n",
    "queries[\"QP1\"] = QP1\n",
    "queries[\"QP2\"] = QP2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busca Léxica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementação de busca esparsa (léxica) com BM25\n",
    "def lexical_search(queries: dict[str, str]):\n",
    "    lexical_results = {}\n",
    "    for query_id, query in queries.items():\n",
    "        \n",
    "        # Pré-processa os dados\n",
    "        for preprocessing_step in preprocessing_steps:\n",
    "            query = preprocessing_step(query)\n",
    "        \n",
    "        search_query = {\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"processed_text\": query\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Realiza a busca\n",
    "        response = es.search(index=index_name, body=search_query)\n",
    "        \n",
    "        hits_results = []\n",
    "        # Recupera os resultados\n",
    "        for hit in response[\"hits\"][\"hits\"]:\n",
    "            hits_results.append((hit[\"_source\"][\"doc_id\"], hit[\"_score\"]))\n",
    "        lexical_results[query_id] = hits_results\n",
    "    \n",
    "    print(lexical_results)\n",
    "    return lexical_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busca Semântica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza busca semântica (densa) com KNN exato\n",
    "def semantic_search(queries: dict[str, str]):\n",
    "    semantic_results = {}\n",
    "    \n",
    "    for query in queries:\n",
    "        # Aplica todos os pré-processamentos aos dados\n",
    "        for preprocessing_step in preprocessing_steps:\n",
    "            query = preprocessing_step(query)\n",
    "            \n",
    "        query_vector = model.encode(query).tolist()\n",
    "        \n",
    "        \n",
    "        search_query = {\n",
    "            \"query\": {\n",
    "                \"script_score\": {\n",
    "                    \"query\": {\"match_all\": {}},\n",
    "                    \"script\": {\n",
    "                        \"source\": \"cosineSimilarity(params.query_vector, 'embeddings') + 1.0\",\n",
    "                        \"params\": {\"query_vector\": query_vector}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Realiza a busca\n",
    "        response = es.search(index=index_name, body=search_query)\n",
    "        \n",
    "        hits_results = []\n",
    "        # Recupera top 10 resultados\n",
    "        for hit in response[\"hits\"][\"hits\"]:\n",
    "            hits_results.append((hit[\"_source\"][\"doc_id\"], hit[\"_score\"]))\n",
    "            \n",
    "        semantic_results[query] = hits_results\n",
    "   \n",
    "    print(semantic_results)\n",
    "    return semantic_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busca Híbrida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca híbrida ou RRF. Implemente sua solução aqui. Você pode realizar as duas buscas anteriores (léxica e semântica) como base para formar a busca híbrida.\n",
    "def hybrid_search(queries: dict[str, str]):\n",
    "    hybrid_results = {}\n",
    "    \n",
    "    for query_id, query in queries.items():\n",
    "        # Aplicar pré-processamentos aos dados, se necessário\n",
    "        processed_query = query\n",
    "        for preprocessing_step in preprocessing_steps:\n",
    "            processed_query = preprocessing_step(processed_query)\n",
    "        \n",
    "        # Obter resultados das buscas léxica e semântica\n",
    "        # Busca léxica\n",
    "        search_query_lexical = {\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"processed_text\": processed_query\n",
    "                }\n",
    "            },\n",
    "            \"size\": 20  # Buscamos mais resultados para ter uma fusão melhor\n",
    "        }\n",
    "        response_lexical = es.search(index=index_name, body=search_query_lexical)\n",
    "        \n",
    "        # Busca semântica\n",
    "        query_vector = model.encode(query).tolist()\n",
    "        search_query_semantic = {\n",
    "            \"knn\": {\n",
    "                \"field\": \"embeddings\",\n",
    "                \"query_vector\": query_vector,\n",
    "                \"k\": 20,\n",
    "                \"num_candidates\": 100\n",
    "            },\n",
    "            \"size\": 20\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response_semantic = es.search(index=index_name, body=search_query_semantic)\n",
    "        except Exception as e:\n",
    "            # Fallback para script_score se KNN falhar\n",
    "            search_query_semantic = {\n",
    "                \"query\": {\n",
    "                    \"script_score\": {\n",
    "                        \"query\": {\"match_all\": {}},\n",
    "                        \"script\": {\n",
    "                            \"source\": \"cosineSimilarity(params.query_vector, 'embeddings') + 1.0\",\n",
    "                            \"params\": {\"query_vector\": query_vector}\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"size\": 20\n",
    "            }\n",
    "            response_semantic = es.search(index=index_name, body=search_query_semantic)\n",
    "        \n",
    "        # Implementação do método Reciprocal Rank Fusion (RRF)\n",
    "        # Parâmetro k do RRF (constante para evitar divisão por zero e para diminuir a influência de ranks muito baixos)\n",
    "        k = 60\n",
    "        \n",
    "        # Dicionário para armazenar os scores RRF\n",
    "        rrf_scores = {}\n",
    "        \n",
    "        # Processar resultados léxicos\n",
    "        for rank, hit in enumerate(response_lexical[\"hits\"][\"hits\"], 1):\n",
    "            doc_id = hit[\"_source\"][\"doc_id\"]\n",
    "            rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + 1.0 / (k + rank)\n",
    "        \n",
    "        # Processar resultados semânticos\n",
    "        for rank, hit in enumerate(response_semantic[\"hits\"][\"hits\"], 1):\n",
    "            doc_id = hit[\"_source\"][\"doc_id\"]\n",
    "            rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + 1.0 / (k + rank)\n",
    "        \n",
    "        # Ordenar os resultados pelo score RRF\n",
    "        sorted_results = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Obter os top 10 resultados\n",
    "        hybrid_results[query_id] = [(doc_id, score) for doc_id, score in sorted_results[:10]]\n",
    "    \n",
    "    return hybrid_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busca Criativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemente sua própria estratégia de busca, podendo ela ser esparsa, densa ou híbrida. Implemente algo como \"more_like_this\", \"BM35\", \"fuzzy\" etc.\n",
    "def creative_search(queries: dict[str, str]):\n",
    "    creative_results = {}\n",
    "    \n",
    "    # Dicionário de expansão de consulta com sinônimos comuns em português\n",
    "    expansion_dict = {\n",
    "        \"covid\": [\"coronavirus\", \"pandemia\", \"sars-cov-2\", \"covid-19\"],\n",
    "        \"vacina\": [\"imunizante\", \"dose\", \"imunização\", \"pfizer\", \"coronavac\", \"astrazeneca\"],\n",
    "        \"fraude\": [\"golpe\", \"enganação\", \"mentira\", \"falso\", \"fake\"],\n",
    "        \"eleição\": [\"pleito\", \"votação\", \"urna\", \"voto\", \"eleitoral\"],\n",
    "        \"governo\": [\"federal\", \"administração\", \"gestão\", \"planalto\", \"brasília\"],\n",
    "        \"imposto\": [\"taxa\", \"tributo\", \"cobrança\", \"fiscal\", \"receita\"]\n",
    "    }\n",
    "    \n",
    "    for query_id, query in queries.items():\n",
    "        # Expandir a consulta com sinônimos\n",
    "        terms = query.lower().split()\n",
    "        expanded_terms = []\n",
    "        \n",
    "        for term in terms:\n",
    "            expanded_terms.append(term)\n",
    "            for key, expansions in expansion_dict.items():\n",
    "                if key in term or term in key:\n",
    "                    expanded_terms.extend(expansions)\n",
    "        \n",
    "        # Remover duplicatas mantendo a ordem\n",
    "        expanded_terms = list(dict.fromkeys(expanded_terms))\n",
    "        \n",
    "        # Construir a consulta criativa\n",
    "        search_query = {\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"should\": [\n",
    "                        # Match phrase com boost alto (frases exatas)\n",
    "                        {\n",
    "                            \"match_phrase\": {\n",
    "                                \"full_text\": {\n",
    "                                    \"query\": query,\n",
    "                                    \"boost\": 3.0\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        # Match com os termos expandidos\n",
    "                        {\n",
    "                            \"match\": {\n",
    "                                \"full_text\": {\n",
    "                                    \"query\": \" \".join(expanded_terms),\n",
    "                                    \"boost\": 1.5\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        # Consulta fuzzy para termos mais longos (tolera erros de digitação)\n",
    "                        {\n",
    "                            \"multi_match\": {\n",
    "                                \"query\": query,\n",
    "                                \"fields\": [\"full_text\", \"processed_text\"],\n",
    "                                \"fuzziness\": \"AUTO\",\n",
    "                                \"boost\": 1.0\n",
    "                            }\n",
    "                        }\n",
    "                    ],\n",
    "                    \"minimum_should_match\": 1\n",
    "                }\n",
    "            },\n",
    "            \"size\": 10\n",
    "        }\n",
    "        \n",
    "        # Realiza a busca\n",
    "        response = es.search(index=index_name, body=search_query)\n",
    "        \n",
    "        hits_results = []\n",
    "        # Recupera os resultados\n",
    "        for hit in response[\"hits\"][\"hits\"]:\n",
    "            doc_id = hit[\"_source\"][\"doc_id\"]\n",
    "            score = hit[\"_score\"]\n",
    "            hits_results.append((doc_id, score))\n",
    "        \n",
    "        creative_results[query_id] = hits_results\n",
    "    \n",
    "    return creative_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execução das buscas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_functions = [\n",
    "    (\"lexical\", lexical_search),\n",
    "    (\"semantic\", semantic_search),\n",
    "    (\"hybrid\", hybrid_search),\n",
    "    (\"creative\", creative_search)\n",
    "]\n",
    "\n",
    "def run_all_searches(queries: dict[str, str]):\n",
    "    all_search_results = {}\n",
    "    for search_name, search_function in search_functions:\n",
    "        results = search_function(queries)\n",
    "        all_search_results[search_name] = results\n",
    "    return all_search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analise os resultados da busca e aprimore a busca!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc_id': 1644, 'full_text': 'Um texto que circula pelas redes sociais diz que os Estados Unidos teriam provado que houve fraude nas eleições de 2022 e que Jair Bolsonaro (PL) venceu a disputa. É falso.\\nPor meio do projeto de verificação de notícias, usuários do Facebook solicitaram que esse material fosse analisado. Confira a seguir o trabalho de verificação da Lupa:\\n“URGENTE! EUA PROVA A VITÓRIA DE BOLSONARO E A FRAUDE DOS ESQUERDOPATA(...) DE FATO COM PROVAS TÉCNICAS E CIENTÍFICAS O PRESIDENTE DA REPÚBLICA É JAIR MESSIAS BOLSONARO”\\nO conteúdo desinformativo não apresenta nenhuma evidência de que Bolsonaro teria vencido a eleição. Em nota enviada à Lupa, a Embaixada dos Estados Unidos negou as informações e enfatizou o respeito pelas instituições democráticas do Brasil. “A Embaixada e Consulados dos EUA informam que a informação publicada é falsa. Ressaltamos também que os EUA reafirmam seu respeito às instituições democráticas brasileiras“, esclareceu, no texto.\\nAlém disso, buscas no Google e Bing pelos termos “fraude\", \"eleição”, “EUA” e “2022” não retornam nenhuma notícia que confirme a publicação de um estudo ou relatório oficial dos Estados Unidos comprovando fraude nas eleições brasileiras, tampouco a vitória de Bolsonaro.\\nVale reforçar que as eleições de 2022 foram acompanhadas por diversas missões de observação eleitoral, formadas por entidades nacionais e internacionais para acompanhar e avaliar as eleições brasileiras. Em diferentes documentos, essas organizações atestaram a segurança do sistema eleitoral.\\nO relatório preliminar da Missão Integrada de Observação Eleitoral da União Interamericana dos Órgãos Eleitorais (Uniore), publicado em 31 de outubro de 2022, por exemplo, atestou a segurança do sistema eletrônico de votação. O relatório final do Conselho Federal da OAB, divulgado em novembro de 2022, também reforçou que o processo eleitoral é limpo e seguro. É possível consultar todos os relatórios das missões no site do TSE.\\nEssa não é a primeira vez que desinformações do gênero circulam na internet. Em novembro de 2022, circulou um estudo — de origem não identificada —, “provando” que houve fraude no primeiro turno das eleições presidenciais. Na época, a Lupa fez uma verificação desmentindo a publicação compartilhada nas redes sociais. Em maio de 2023, a Lupa também mostrou que era falso um estudo dos EUA que comprovaria a vitória de Bolsonaro nas urnas.\\nEsse mesmo conteúdo foi verificado por Boatos.org e Aos Fatos.\\nÉ falso que Estados Unidos provaram vitória de Bolsonaro nas eleições de 2022', 'processed_text': 'Um texto que circula pelas redes sociais diz que os Estados Unidos teriam provado que houve fraude nas eleições de 2022 e que Jair Bolsonaro (PL) venceu a disputa. É falso.\\nPor meio do projeto de verificação de notícias, usuários do Facebook solicitaram que esse material fosse analisado. Confira a seguir o trabalho de verificação da Lupa:\\n“URGENTE! EUA PROVA A VITÓRIA DE BOLSONARO E A FRAUDE DOS ESQUERDOPATA(...) DE FATO COM PROVAS TÉCNICAS E CIENTÍFICAS O PRESIDENTE DA REPÚBLICA É JAIR MESSIAS BOLSONARO”\\nO conteúdo desinformativo não apresenta nenhuma evidência de que Bolsonaro teria vencido a eleição. Em nota enviada à Lupa, a Embaixada dos Estados Unidos negou as informações e enfatizou o respeito pelas instituições democráticas do Brasil. “A Embaixada e Consulados dos EUA informam que a informação publicada é falsa. Ressaltamos também que os EUA reafirmam seu respeito às instituições democráticas brasileiras“, esclareceu, no texto.\\nAlém disso, buscas no Google e Bing pelos termos “fraude\", \"eleição”, “EUA” e “2022” não retornam nenhuma notícia que confirme a publicação de um estudo ou relatório oficial dos Estados Unidos comprovando fraude nas eleições brasileiras, tampouco a vitória de Bolsonaro.\\nVale reforçar que as eleições de 2022 foram acompanhadas por diversas missões de observação eleitoral, formadas por entidades nacionais e internacionais para acompanhar e avaliar as eleições brasileiras. Em diferentes documentos, essas organizações atestaram a segurança do sistema eleitoral.\\nO relatório preliminar da Missão Integrada de Observação Eleitoral da União Interamericana dos Órgãos Eleitorais (Uniore), publicado em 31 de outubro de 2022, por exemplo, atestou a segurança do sistema eletrônico de votação. O relatório final do Conselho Federal da OAB, divulgado em novembro de 2022, também reforçou que o processo eleitoral é limpo e seguro. É possível consultar todos os relatórios das missões no site do TSE.\\nEssa não é a primeira vez que desinformações do gênero circulam na internet. Em novembro de 2022, circulou um estudo — de origem não identificada —, “provando” que houve fraude no primeiro turno das eleições presidenciais. Na época, a Lupa fez uma verificação desmentindo a publicação compartilhada nas redes sociais. Em maio de 2023, a Lupa também mostrou que era falso um estudo dos EUA que comprovaria a vitória de Bolsonaro nas urnas.\\nEsse mesmo conteúdo foi verificado por Boatos.org e Aos Fatos.\\nÉ falso que Estados Unidos provaram vitória de Bolsonaro nas eleições de 2022', 'embeddings': [-0.14809289574623108, 0.10177648067474365, -0.2589673101902008, -0.08237050473690033, 0.25322386622428894, 0.11950111389160156, -0.0257094893604517, 0.003474282566457987, 0.11066950857639313, 0.14679430425167084, 0.11789289116859436, 0.08116471022367477, 0.09657687693834305, 0.08449193090200424, -0.009060569107532501, -0.022275498136878014, -0.11641182005405426, -0.11324530839920044, 0.022709500044584274, 0.19549891352653503, 0.11241038143634796, -0.05783982202410698, 0.07426024973392487, -0.04076707735657692, 0.20308132469654083, 0.007212763652205467, 0.03460393100976944, -0.14947503805160522, -0.1303337812423706, -0.14381828904151917, 0.0683555155992508, 0.00582282617688179, 0.11584100872278214, 0.06054670363664627, 0.11952479183673859, -0.17022109031677246, 0.1964704841375351, 0.03745557367801666, 0.1082695797085762, 0.057478152215480804, -0.12113998830318451, -0.08542121201753616, -0.02250034734606743, 0.019150760024785995, 0.15234512090682983, 0.08624137938022614, 0.051228027790784836, 0.1603180319070816, -0.14722822606563568, -0.010447992943227291, -0.005481826141476631, 0.05990292504429817, -0.08325693011283875, -0.09703482687473297, -0.03940052539110184, -0.1095631942152977, 0.04069007933139801, -0.005389940459281206, -0.08500726521015167, -0.02826104499399662, 0.06498711556196213, 0.09648291021585464, 0.06884202361106873, 0.010430797934532166, 0.004226705525070429, -0.03906286135315895, 0.031498983502388, -0.09573711454868317, 0.011420747265219688, 0.10786530375480652, 0.09183529019355774, -0.05023379623889923, 0.011622309684753418, -0.025193780660629272, 0.038274992257356644, -0.049103256314992905, -0.05814528092741966, 0.19730053842067719, 0.07523564994335175, -0.10254882276058197, 0.28626781702041626, 0.09768761694431305, 0.011839127168059349, -0.12016687542200089, -0.06063995510339737, -0.13785342872142792, 0.054718296974897385, 0.019258536398410797, 0.060381270945072174, -0.2988241910934448, -0.033240512013435364, -0.015696540474891663, 0.2303885519504547, 0.01385468803346157, 0.05905519053339958, -0.025785962119698524, 0.004161568824201822, 0.11665165424346924, 0.15497970581054688, 0.08181416988372803, -0.23314478993415833, 0.0487113818526268, -0.1291288584470749, -0.13933390378952026, 0.1252562403678894, 0.1105707436800003, 0.01957005448639393, -0.0584862194955349, -0.006672351621091366, -0.006742430850863457, -0.05007058009505272, -0.0659906417131424, -0.006335766054689884, 0.008396734483540058, 0.12141743302345276, -0.0883263573050499, 0.018702665343880653, -0.07586771994829178, -0.15020133554935455, 0.12187064439058304, -0.03344728425145149, -0.14293205738067627, 0.05908794701099396, -0.059165243059396744, 0.14327643811702728, -0.14291390776634216, -0.028874292969703674, 0.008413710631430149, 0.11440153419971466, -0.16270136833190918, -0.09717175364494324, 0.01785365492105484, -0.12139150500297546, 0.16148056089878082, -0.06981578469276428, -0.1649765819311142, 0.10208490490913391, 0.1039453074336052, -0.11484827101230621, 0.0169929638504982, -0.03901029750704765, 0.13574010133743286, 0.04417280852794647, 0.2188795506954193, -0.1897301822900772, 0.023828569799661636, 0.10554349422454834, -0.1097852811217308, 0.11929458379745483, 0.0708012804389, 0.3197583258152008, -0.012645957060158253, 0.06594308465719223, 0.1521201729774475, 0.06392571330070496, 0.027343744412064552, 0.04914276301860809, 0.07496737688779831, -0.12460262328386307, 0.01979820616543293, 0.05698826164007187, 0.10635781288146973, -0.007125108502805233, 0.07210652530193329, 0.13923656940460205, -0.0778806135058403, 0.07869219779968262, -0.05612945556640625, 0.12319941073656082, 0.08451463282108307, 0.05816161260008812, 0.003856546711176634, -0.05403721705079079, -0.04134150967001915, 0.008527706377208233, -0.13389243185520172, -0.014827430248260498, 0.06650765240192413, -0.0667169839143753, 0.050237417221069336, 0.045247942209243774, -0.15626072883605957, 0.014181261882185936, -0.06849335879087448, 0.006478690542280674, 0.039748094975948334, -0.030160903930664062, -0.12344570457935333, -0.07030431181192398, -0.027578052133321762, -0.12539495527744293, -0.00825988408178091, -0.06560376286506653, 0.09404037892818451, -0.14657941460609436, -0.021907970309257507, 0.04044597968459129, 0.03367378190159798, 0.06171909719705582, -0.10953644663095474, -0.2805540859699249, -0.17872673273086548, -0.2498624324798584, -0.19921348989009857, 0.034419599920511246, -0.17153692245483398, -0.03898058086633682, -0.08783228695392609, 0.019406674429774284, -0.0037975856103003025, 0.24505960941314697, -0.07114270329475403, -0.1330619752407074, -0.031048962846398354, 0.06026759743690491, 0.003551923669874668, -0.02020413428544998, 0.13500511646270752, -0.13040341436862946, 0.018346253782510757, -0.013405818492174149, -0.13736318051815033, 0.051386453211307526, -0.135158509016037, -0.3180995285511017, -0.03383037447929382, -0.04822941869497299, 0.09700218588113785, 0.026641398668289185, -0.031233353540301323, -0.11589140444993973, -0.03597034513950348, 0.013846301473677158, -0.13258256018161774, -0.030273066833615303, -0.1727592498064041, 0.0518200658261776, 0.06840589642524719, -0.18156686425209045, -0.05378713086247444, -0.058716416358947754, -0.047341786324977875, -0.006539598107337952, -0.07903297245502472, 0.11797261238098145, -0.11273564398288727, -0.13346335291862488, 0.1035882979631424, -0.031433768570423126, 0.051056213676929474, 0.016335535794496536, -0.3619251251220703, 0.0393604040145874, -0.09710880368947983, 0.09210918843746185, 0.08636006712913513, -0.0028703161515295506, 0.1376945525407791, 0.17558619379997253, 0.054962992668151855, 0.0596010759472847, -0.025507576763629913, -0.024664314463734627, -0.16466602683067322, 0.0754028856754303, 0.00965536292642355, -0.09693166613578796, 0.07233897596597672, -0.07336649298667908, 0.05010756850242615, -0.14691612124443054, -0.019447222352027893, 0.2176664024591446, -0.07888928055763245, 0.1090627908706665, -0.07307165861129761, -0.03181832656264305, -0.01052026730030775, -0.21815192699432373, 0.10071784257888794, -0.034369491040706635, -0.02820020169019699, 0.1784001588821411, -0.047717753797769547, 0.02001343108713627, -0.09043750166893005, 0.029570287093520164, -0.09922988712787628, 0.14027747511863708, 0.15706899762153625, -0.04905899614095688, 0.14715451002120972, 0.27500051259994507, 0.02864745259284973, 0.12392303347587585, -0.09106498211622238, -0.1461390256881714, 0.10631705820560455, 0.05765217915177345, 0.19121083617210388, -0.152186319231987, 0.13342319428920746, 0.014417297206819057, 0.05926446244120598, 0.21007925271987915, -0.008935259655117989, 0.10792501270771027, 0.045101068913936615, 0.12148366123437881, 0.03819037228822708, 0.04839520528912544, -0.27124929428100586, -0.09902758151292801, 0.12275104224681854, 0.16429752111434937, -0.08635985851287842, 0.03067212738096714, 0.10985790193080902, 0.10902145504951477, -0.1893356442451477, 0.104763925075531, -0.07461120188236237, 0.026577463373541832, 0.04045593738555908, 0.07310105860233307, 0.09783844649791718, -0.037755776196718216, -0.11538112163543701, -0.032556816935539246, -0.10984599590301514, 0.015720106661319733, 0.05557003989815712, -0.05426177754998207, -0.14407232403755188, 0.032531093806028366, 0.031855907291173935, -0.13922841846942902, 0.024495545774698257, 0.033211108297109604, 0.0679263323545456, 0.04366447404026985, 0.09801054000854492, -0.15203753113746643, -0.11621303856372833, 0.07162663340568542, 0.11209225654602051, -0.03891140967607498, 0.1941586136817932, -0.11054626107215881, 0.0009507555514574051, -0.13257580995559692, -0.08887343108654022, -0.10348232835531235, -0.05387095361948013, -0.1157306358218193, 0.05065816268324852, 0.03953538462519646, -0.008004956878721714, 0.08644192665815353, -0.18901722133159637, 0.13091245293617249, 0.06979408115148544, -0.09661159664392471, 0.051687538623809814, 0.0022809067741036415, 0.011733363382518291, -0.11121571063995361, 0.012366881594061852, 0.03261047601699829, -0.005423642694950104, -0.10651178658008575, -0.1183050349354744, 0.03429166227579117, -0.12580221891403198, 0.19819600880146027, -0.09493197500705719, 0.02343098446726799, 0.026451466605067253, 0.010800439864397049, 0.022916758432984352, 0.05735812708735466, 0.0021161804907023907, 0.04587125405669212, 0.0550045371055603]}\n"
     ]
    }
   ],
   "source": [
    "# all_search_results = run_all_searches(queries)\n",
    "# search_results_df = pd.DataFrame(all_search_results)\n",
    "# search_results_df\n",
    "\n",
    "documento = es.get(index=index_name, id=1644)\n",
    "print(documento[\"_source\"])  # Exibe o conteúdo do documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados das buscas salvos em 'data/search_results.csv'.\n",
      "Documentos de interesse salvos em 'data/documents.csv'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical</th>\n",
       "      <th>semantic</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>creative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QF1</th>\n",
       "      <td>1920</td>\n",
       "      <td>1897</td>\n",
       "      <td>1920</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF1</th>\n",
       "      <td>1766</td>\n",
       "      <td>3822</td>\n",
       "      <td>1606</td>\n",
       "      <td>2650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF1</th>\n",
       "      <td>623</td>\n",
       "      <td>1037</td>\n",
       "      <td>1586</td>\n",
       "      <td>3648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF1</th>\n",
       "      <td>1991</td>\n",
       "      <td>3492</td>\n",
       "      <td>1491</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF1</th>\n",
       "      <td>4090</td>\n",
       "      <td>1444</td>\n",
       "      <td>1766</td>\n",
       "      <td>3661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF1</th>\n",
       "      <td>1586</td>\n",
       "      <td>1423</td>\n",
       "      <td>82</td>\n",
       "      <td>1766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF1</th>\n",
       "      <td>1606</td>\n",
       "      <td>3949</td>\n",
       "      <td>623</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF1</th>\n",
       "      <td>2898</td>\n",
       "      <td>5041</td>\n",
       "      <td>1991</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF1</th>\n",
       "      <td>1461</td>\n",
       "      <td>5027</td>\n",
       "      <td>4090</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF1</th>\n",
       "      <td>867</td>\n",
       "      <td>5014</td>\n",
       "      <td>2547</td>\n",
       "      <td>3502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF2</th>\n",
       "      <td>3761</td>\n",
       "      <td>5041</td>\n",
       "      <td>3710</td>\n",
       "      <td>3092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF2</th>\n",
       "      <td>3710</td>\n",
       "      <td>3486</td>\n",
       "      <td>3461</td>\n",
       "      <td>3847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF2</th>\n",
       "      <td>1940</td>\n",
       "      <td>4924</td>\n",
       "      <td>3761</td>\n",
       "      <td>1096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF2</th>\n",
       "      <td>3461</td>\n",
       "      <td>1897</td>\n",
       "      <td>2972</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF2</th>\n",
       "      <td>3726</td>\n",
       "      <td>4314</td>\n",
       "      <td>2995</td>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF2</th>\n",
       "      <td>3457</td>\n",
       "      <td>5128</td>\n",
       "      <td>3692</td>\n",
       "      <td>3903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF2</th>\n",
       "      <td>3251</td>\n",
       "      <td>5014</td>\n",
       "      <td>1940</td>\n",
       "      <td>3761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF2</th>\n",
       "      <td>1398</td>\n",
       "      <td>4698</td>\n",
       "      <td>3409</td>\n",
       "      <td>2947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF2</th>\n",
       "      <td>2854</td>\n",
       "      <td>1037</td>\n",
       "      <td>3726</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QF2</th>\n",
       "      <td>4618</td>\n",
       "      <td>4456</td>\n",
       "      <td>3457</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP1</th>\n",
       "      <td>141</td>\n",
       "      <td>5027</td>\n",
       "      <td>1162</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP1</th>\n",
       "      <td>978</td>\n",
       "      <td>5104</td>\n",
       "      <td>141</td>\n",
       "      <td>1665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP1</th>\n",
       "      <td>191</td>\n",
       "      <td>4380</td>\n",
       "      <td>1059</td>\n",
       "      <td>2033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP1</th>\n",
       "      <td>201</td>\n",
       "      <td>3949</td>\n",
       "      <td>978</td>\n",
       "      <td>1162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP1</th>\n",
       "      <td>2033</td>\n",
       "      <td>3300</td>\n",
       "      <td>2880</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP1</th>\n",
       "      <td>1162</td>\n",
       "      <td>5041</td>\n",
       "      <td>191</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP1</th>\n",
       "      <td>1040</td>\n",
       "      <td>4698</td>\n",
       "      <td>201</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP1</th>\n",
       "      <td>1088</td>\n",
       "      <td>4924</td>\n",
       "      <td>2158</td>\n",
       "      <td>3703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP1</th>\n",
       "      <td>1665</td>\n",
       "      <td>3244</td>\n",
       "      <td>2033</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP1</th>\n",
       "      <td>1049</td>\n",
       "      <td>3856</td>\n",
       "      <td>1051</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP2</th>\n",
       "      <td>1644</td>\n",
       "      <td>5041</td>\n",
       "      <td>887</td>\n",
       "      <td>2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP2</th>\n",
       "      <td>887</td>\n",
       "      <td>4924</td>\n",
       "      <td>1543</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP2</th>\n",
       "      <td>982</td>\n",
       "      <td>5027</td>\n",
       "      <td>982</td>\n",
       "      <td>1543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP2</th>\n",
       "      <td>1543</td>\n",
       "      <td>3486</td>\n",
       "      <td>1323</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP2</th>\n",
       "      <td>2270</td>\n",
       "      <td>4698</td>\n",
       "      <td>2273</td>\n",
       "      <td>2288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP2</th>\n",
       "      <td>548</td>\n",
       "      <td>5128</td>\n",
       "      <td>1683</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP2</th>\n",
       "      <td>2260</td>\n",
       "      <td>5006</td>\n",
       "      <td>1644</td>\n",
       "      <td>1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP2</th>\n",
       "      <td>1470</td>\n",
       "      <td>4314</td>\n",
       "      <td>764</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP2</th>\n",
       "      <td>2288</td>\n",
       "      <td>5104</td>\n",
       "      <td>2179</td>\n",
       "      <td>2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QP2</th>\n",
       "      <td>2223</td>\n",
       "      <td>4380</td>\n",
       "      <td>2270</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lexical  semantic  hybrid  creative\n",
       "QF1     1920      1897    1920      1920\n",
       "QF1     1766      3822    1606      2650\n",
       "QF1      623      1037    1586      3648\n",
       "QF1     1991      3492    1491      1945\n",
       "QF1     4090      1444    1766      3661\n",
       "QF1     1586      1423      82      1766\n",
       "QF1     1606      3949     623      1422\n",
       "QF1     2898      5041    1991      1991\n",
       "QF1     1461      5027    4090       447\n",
       "QF1      867      5014    2547      3502\n",
       "QF2     3761      5041    3710      3092\n",
       "QF2     3710      3486    3461      3847\n",
       "QF2     1940      4924    3761      1096\n",
       "QF2     3461      1897    2972      1228\n",
       "QF2     3726      4314    2995      3262\n",
       "QF2     3457      5128    3692      3903\n",
       "QF2     3251      5014    1940      3761\n",
       "QF2     1398      4698    3409      2947\n",
       "QF2     2854      1037    3726       981\n",
       "QF2     4618      4456    3457       399\n",
       "QP1      141      5027    1162       978\n",
       "QP1      978      5104     141      1665\n",
       "QP1      191      4380    1059      2033\n",
       "QP1      201      3949     978      1162\n",
       "QP1     2033      3300    2880       399\n",
       "QP1     1162      5041     191      1945\n",
       "QP1     1040      4698     201       195\n",
       "QP1     1088      4924    2158      3703\n",
       "QP1     1665      3244    2033       141\n",
       "QP1     1049      3856    1051      1088\n",
       "QP2     1644      5041     887      2273\n",
       "QP2      887      4924    1543       217\n",
       "QP2      982      5027     982      1543\n",
       "QP2     1543      3486    1323       887\n",
       "QP2     2270      4698    2273      2288\n",
       "QP2      548      5128    1683       982\n",
       "QP2     2260      5006    1644      1644\n",
       "QP2     1470      4314     764       548\n",
       "QP2     2288      5104    2179      2270\n",
       "QP2     2223      4380    2270       213"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_exploded_df(search_results_df):\n",
    "    exploded_search_results_df = pd.concat([search_results_df[col].explode() for col in search_results_df.columns], axis=1)\n",
    "    exploded_search_results_df = exploded_search_results_df.apply(lambda l: [doc_id for doc_id, _ in l])\n",
    "    return exploded_search_results_df\n",
    "\n",
    "def generate_found_docs_text_df(exploded_search_results_df, all_docs_df):\n",
    "    # Recupera os ids únicos dos documentos\n",
    "    documents_ids = set(exploded_search_results_df.to_numpy().flatten().tolist())\n",
    "\n",
    "    # Salva os textos e os ids dos documetnos que foram encontrados ems usas buscas\n",
    "    documents_df = all_docs_df[all_docs_df[\"doc_id\"].isin(documents_ids)][[\"Texto processado\", \"doc_id\"]]\n",
    "    return documents_df\n",
    "\n",
    "exploded_df = generate_exploded_df(search_results_df)\n",
    "found_docs_text_df = generate_found_docs_text_df(exploded_df, all_docs_df=df)\n",
    "\n",
    "def save_results_to_file(exploded_df: pd.DataFrame,\n",
    "                         found_docs_text_df: pd.DataFrame,\n",
    "                         exploded_df_save_filepath: str = \"data/search_results.csv\",\n",
    "                         found_docs_text_save_filepath: str = \"data/documents.csv\"):\n",
    "    exploded_df.to_csv(exploded_df_save_filepath)\n",
    "    found_docs_text_df.to_csv(found_docs_text_save_filepath)\n",
    "    print(\"Resultados das buscas salvos em 'data/search_results.csv'.\")\n",
    "    print(\"Documentos de interesse salvos em 'data/documents.csv'.\")\n",
    "    \n",
    "save_results_to_file(exploded_df, found_docs_text_df)\n",
    "exploded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anote as relevâncias na sua planilha!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 3: Reexecutar a busca para as novas queries e rotular os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencha aqui com as queries adicionais do seu grupo\n",
    "QA1 = XXXXXXXXX\n",
    "QA2 = XXXXXXXXX\n",
    "QA3 = XXXXXXXXX\n",
    "\n",
    "queries = OrderedDict()\n",
    "queries[\"QF1\"] = QF1\n",
    "queries[\"QF2\"] = QF2\n",
    "queries[\"QA1\"] = QA1\n",
    "queries[\"QA2\"] = QA2\n",
    "queries[\"QA3\"] = QA3\n",
    "\n",
    "\n",
    "all_search_results = run_all_searches(queries)\n",
    "search_results_df = pd.DataFrame(all_search_results)\n",
    "search_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df = generate_exploded_df(search_results_df)\n",
    "found_docs_text_df = generate_found_docs_text_df(exploded_df, all_docs_df=df)\n",
    "\n",
    "def save_results_to_file(exploded_df: pd.DataFrame,\n",
    "                         found_docs_text_df: pd.DataFrame,\n",
    "                         exploded_df_save_filepath: str = \"data/search_results.csv\",\n",
    "                         found_docs_text_save_filepath: str = \"data/documents.csv\"):\n",
    "    exploded_df.to_csv(exploded_df_save_filepath)\n",
    "    found_docs_text_df.to_csv(found_docs_text_save_filepath)\n",
    "    print(\"Resultados das buscas salvos em 'data/search_results.csv'.\")\n",
    "    print(\"Documentos de interesse salvos em 'data/documents.csv'.\")\n",
    "    \n",
    "save_results_to_file(exploded_df, found_docs_text_df)\n",
    "exploded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anote os resultados na sua planilha!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A competição utilizará o NDCG médio por query para computar seu desempenho."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
